
!pip install ultralytics opencv-python tensorflow onnxruntime rembg

import torch
from google.colab import drive
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import Model
from sklearn.neighbors import NearestNeighbors
from rembg import remove
import os
from sklearn.metrics import classification_report, accuracy_score
from collections import Counter
from ultralytics import YOLO

# Mount Google Drive
drive.mount('/content/drive')

# Load YOLOv8x model (consistent with feature extraction)
yolo_model = YOLO('yolov8x.pt')

# Load model and features
model = tf.keras.models.load_model("/content/drive/MyDrive/model3/resnet_vehicle_model18.keras") 
feature_extractor = Model(inputs=model.input, outputs=model.layers[-3].output)
train_features = np.load("/content/drive/MyDrive/model3/resnet_train_features18.npy")
train_labels = np.load("/content/drive/MyDrive/model3/resnet_train_labels18.npy")

# Initialize Nearest Neighbors
nn = NearestNeighbors(n_neighbors=3, metric='cosine')
nn.fit(train_features)

# Preprocessing function (matches training/feature extraction: pure grayscale, histogram equalization, edge overlay)
def preprocess_image(img):
    # Ensure input is in uint8 format
    if img.dtype != np.uint8:
        img = img.astype(np.uint8)

    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

    # Histogram Equalization
    equalized = cv2.equalizeHist(gray)

    # Edge Detection
    edges = cv2.Canny(equalized, 5000, 1000, apertureSize=5, L2gradient=True)
    kernel = np.ones((1, 1), np.uint8)
    closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)

    # Overlay edges on grayscale image
    overlay = equalized.copy()
    overlay[closed_edges == 255] = 255  # Highlight edges in white

    # Convert single-channel grayscale back to 3-channel image for ResNet
    overlay_3ch = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)

    # Apply ResNet preprocessing
    return tf.keras.applications.resnet50.preprocess_input(overlay_3ch)

# Prediction function
def predict_image(image_path):
    # Read and convert image to RGB
    img = cv2.imread(image_path)
    if img is None:
        return "Error: Could not read image.", 0.0
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Remove background
    img_no_bg = remove(img_rgb)
    img_no_bg = cv2.cvtColor(np.array(img_no_bg), cv2.COLOR_RGBA2RGB)

    # YOLOv8 detection
    results = yolo_model(img_no_bg)

    detected_features = []
    for result in results:
        # Extract bounding box information
        boxes = result.boxes.xyxy.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy()
        confs = result.boxes.conf.cpu().numpy()

        for box, cls, conf in zip(boxes, classes, confs):
            # Filter for cars (class 2) with confidence > 50%
            if int(cls) == 2 and conf > 0.5:
                x1, y1, x2, y2 = map(int, box)

                try:
                    # Crop and process detected vehicle
                    cropped = img_no_bg[y1:y2, x1:x2]
                    resized = cv2.resize(cropped, (224, 224))
                    processed = preprocess_image(resized)

                    # Extract features
                    feature = feature_extractor.predict(np.expand_dims(processed, 0), verbose=0)
                    detected_features.append(feature.flatten())
                except Exception as e:
                    print(f"Error processing car in {image_path}: {str(e)}")
                    continue

    if not detected_features:
        return "No features extracted or no cars detected.", 0.0

    # Get nearest neighbors
    distances, indices = nn.kneighbors(np.array(detected_features))
    all_neighbors = train_labels[indices.flatten()]
    label_counts = Counter(all_neighbors)
    final_pred = label_counts.most_common(1)[0][0]
    confidence = label_counts.most_common(1)[0][1] / len(all_neighbors)

    return final_pred, confidence

# Test dataset path
test_dir = "/content/drive/MyDrive/last_last_test"

# Get class names
class_names = sorted(os.listdir(test_dir))

y_true = []
y_pred = []

for class_name in class_names:
    class_path = os.path.join(test_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    for img_file in os.listdir(class_path):
        img_path = os.path.join(class_path, img_file)
        prediction, conf = predict_image(img_path)

        if prediction in ["Error: Could not read image.", "No features extracted or no cars detected."]:
            print(f"Skipped {img_file}: {prediction}")
            continue

        y_true.append(class_name)
        y_pred.append(prediction)
        print(f"Processed {img_file}: Predicted {prediction} (True: {class_name}), Confidence: {conf:.2f}")

# Calculate metrics
print("\nFinal Metrics:")
print(f"Accuracy: {accuracy_score(y_true, y_pred):.4f}")
try:
    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))
except ValueError as e:
    print(f"Error in classification report: {str(e)}")